"""
ëª¨ë¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

í•™ìŠµëœ ëª¨ë¸ì„ ë‹¤ì–‘í•œ ì‹œë“œì—ì„œ í‰ê°€í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
"""

import gymnasium as gym
from stable_baselines3 import PPO, SAC, TD3
import numpy as np
import pandas as pd
from tqdm import tqdm
import json
import os

from config import (
    FIXED_SEED,
    TEST_SEEDS,
    FIXED_SEED_ENV_CONFIG,
    EVALUATION_CONFIG,
)
from utils.path_utils import get_result_path
from envs.metadrive_env import make_env


def detect_algorithm(model_path):
    """
    ëª¨ë¸ íŒŒì¼ëª…ì—ì„œ ì•Œê³ ë¦¬ì¦˜ ìë™ ê°ì§€
    
    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        str: ì•Œê³ ë¦¬ì¦˜ ì´ë¦„ ('ppo', 'sac', 'td3')
    """
    model_name = os.path.basename(model_path).lower()
    
    if 'sac' in model_name:
        return 'sac'
    elif 'td3' in model_name:
        return 'td3'
    elif 'ppo' in model_name:
        return 'ppo'
    else:
        # ê¸°ë³¸ê°’ì€ PPO
        return 'ppo'


def load_model(model_path, algorithm=None):
    """
    ì•Œê³ ë¦¬ì¦˜ì— ë§ëŠ” ëª¨ë¸ ë¡œë“œ
    
    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        algorithm: ì•Œê³ ë¦¬ì¦˜ ì´ë¦„ (Noneì´ë©´ ìë™ ê°ì§€)
    
    Returns:
        model: ë¡œë“œëœ ëª¨ë¸
    
    Raises:
        ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•Œê³ ë¦¬ì¦˜
    """
    if algorithm is None:
        algorithm = detect_algorithm(model_path)
    
    algorithm = algorithm.lower()
    
    if algorithm == 'ppo':
        return PPO.load(model_path)
    elif algorithm == 'sac':
        return SAC.load(model_path)
    elif algorithm == 'td3':
        return TD3.load(model_path)
    else:
        raise ValueError(
            f"Unsupported algorithm: {algorithm}. "
            f"Choose from: ppo, sac, td3"
        )


def evaluate_model(model_path, test_seeds, n_episodes=20, render=False, verbose=True):
    """
    ëª¨ë¸ì„ ì—¬ëŸ¬ ì‹œë“œì—ì„œ í‰ê°€
    
    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        test_seeds: í…ŒìŠ¤íŠ¸í•  ì‹œë“œ ë¦¬ìŠ¤íŠ¸
        n_episodes: ê° ì‹œë“œë‹¹ ì—í”¼ì†Œë“œ ìˆ˜
        render: ë Œë”ë§ ì—¬ë¶€
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        dict: í‰ê°€ ê²°ê³¼
    """
    if verbose:
        print("\n" + "="*60)
        print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì‹œì‘")
        print("="*60)
        print(f"ëª¨ë¸: {model_path}")
        print(f"í…ŒìŠ¤íŠ¸ ì‹œë“œ: {test_seeds}")
        print(f"ì—í”¼ì†Œë“œ/ì‹œë“œ: {n_episodes}")
        print("="*60 + "\n")
    
    # ëª¨ë¸ ë¡œë“œ (ì•Œê³ ë¦¬ì¦˜ ìë™ ê°ì§€)
    try:
        algorithm = detect_algorithm(model_path)
        if verbose:
            print(f"ğŸ” ê°ì§€ëœ ì•Œê³ ë¦¬ì¦˜: {algorithm.upper()}")
        
        model = load_model(model_path, algorithm)
        if verbose:
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    # ê²°ê³¼ ì €ì¥
    results = {
        "model_path": model_path,
        "test_seeds": test_seeds,
        "n_episodes": n_episodes,
        "seed_results": {},
        "summary": {}
    }
    
    # ê° ì‹œë“œë³„ í‰ê°€
    for seed in test_seeds:
        if verbose:
            print(f"\nğŸ¯ ì‹œë“œ {seed} í‰ê°€ ì¤‘...")
        
        # í™˜ê²½ ìƒì„± (make_env ì‚¬ìš©)
        env = make_env(seed=seed, render=render)()
        
        # ì—í”¼ì†Œë“œë³„ ê²°ê³¼
        episode_rewards = []
        episode_lengths = []
        success_count = 0
        crash_count = 0
        out_of_road_count = 0
        
        # ì§„í–‰ ë°”
        iterator = tqdm(range(n_episodes), desc=f"Seed {seed}") if verbose else range(n_episodes)
        
        for episode in iterator:
            obs, info = env.reset()
            done = False
            total_reward = 0
            steps = 0
            
            while not done:
                action, _ = model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = env.step(action)
                done = terminated or truncated
                total_reward += reward
                steps += 1
            
            # ê²°ê³¼ ê¸°ë¡
            episode_rewards.append(total_reward)
            episode_lengths.append(steps)
            
            if info.get("arrive_dest", False):
                success_count += 1
            if info.get("crash", False):
                crash_count += 1
            if info.get("out_of_road", False):
                out_of_road_count += 1
        
        env.close()
        
        # ì‹œë“œë³„ í†µê³„
        seed_stats = {
            "mean_reward": np.mean(episode_rewards),
            "std_reward": np.std(episode_rewards),
            "min_reward": np.min(episode_rewards),
            "max_reward": np.max(episode_rewards),
            "mean_length": np.mean(episode_lengths),
            "success_rate": success_count / n_episodes,
            "crash_rate": crash_count / n_episodes,
            "out_of_road_rate": out_of_road_count / n_episodes,
            "episode_rewards": episode_rewards,
            "episode_lengths": episode_lengths,
        }
        
        results["seed_results"][seed] = seed_stats
        
        if verbose:
            print(f"\n  í‰ê·  ë³´ìƒ: {seed_stats['mean_reward']:.2f} Â± {seed_stats['std_reward']:.2f}")
            print(f"  ì„±ê³µë¥ : {seed_stats['success_rate']*100:.1f}%")
            print(f"  ì¶©ëŒë¥ : {seed_stats['crash_rate']*100:.1f}%")
    
    # ì „ì²´ ìš”ì•½ í†µê³„
    all_rewards = []
    all_success_rates = []
    
    for seed_stats in results["seed_results"].values():
        all_rewards.extend(seed_stats["episode_rewards"])
        all_success_rates.append(seed_stats["success_rate"])
    
    results["summary"] = {
        "overall_mean_reward": np.mean(all_rewards),
        "overall_std_reward": np.std(all_rewards),
        "overall_success_rate": np.mean(all_success_rates),
        "success_rate_std": np.std(all_success_rates),
    }
    
    if verbose:
        print("\n" + "="*60)
        print("ğŸ“ˆ ì „ì²´ ìš”ì•½")
        print("="*60)
        print(f"ì „ì²´ í‰ê·  ë³´ìƒ: {results['summary']['overall_mean_reward']:.2f} Â± {results['summary']['overall_std_reward']:.2f}")
        print(f"ì „ì²´ í‰ê·  ì„±ê³µë¥ : {results['summary']['overall_success_rate']*100:.1f}% Â± {results['summary']['success_rate_std']*100:.1f}%")
        
        # ì„±ê³µë¥ ì´ 0%ì¼ ë•Œ ê²½ê³  ë©”ì‹œì§€
        if results['summary']['overall_success_rate'] == 0:
            print("\nâš ï¸  ê²½ê³ : ì„±ê³µë¥ ì´ 0%ì…ë‹ˆë‹¤!")
            print("ğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:")
            print("   1. í•™ìŠµì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ (ë” ë§ì€ ìŠ¤í… í•„ìš”)")
            print("   2. ëª¨ë¸ì´ ì œëŒ€ë¡œ í•™ìŠµë˜ì§€ ì•ŠìŒ")
            print("   3. ì—ì´ì „íŠ¸ê°€ í•­ìƒ ë„ë¡œë¥¼ ë²—ì–´ë‚¨")
            print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
            print("   1. TensorBoardë¡œ í•™ìŠµ ê³¡ì„  í™•ì¸:")
            print("      tensorboard --logdir logs/")
            print("   2. ë” ê¸´ í•™ìŠµ ì‹¤í–‰:")
            print("      python train.py --mode fixed  # 100K ìŠ¤í…")
            print("   3. ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:")
            print("      python debug_results.py --results results/evaluation_results.json")
        
        print("="*60 + "\n")
    
    return results


def compare_seeds(results, train_seed=FIXED_SEED):
    """
    í•™ìŠµ ì‹œë“œì™€ í…ŒìŠ¤íŠ¸ ì‹œë“œ ì„±ëŠ¥ ë¹„êµ
    
    Args:
        results: evaluate_model ê²°ê³¼
        train_seed: í•™ìŠµì— ì‚¬ìš©í•œ ì‹œë“œ
    """
    print("\n" + "="*60)
    print("ğŸ” ì‹œë“œë³„ ì„±ëŠ¥ ë¹„êµ")
    print("="*60)
    
    # í•™ìŠµ ì‹œë“œ ì„±ëŠ¥
    if train_seed in results["seed_results"]:
        train_stats = results["seed_results"][train_seed]
        print(f"\nğŸ“š í•™ìŠµ ì‹œë“œ ({train_seed}):")
        print(f"  í‰ê·  ë³´ìƒ: {train_stats['mean_reward']:.2f}")
        print(f"  ì„±ê³µë¥ : {train_stats['success_rate']*100:.1f}%")
    
    # í…ŒìŠ¤íŠ¸ ì‹œë“œ ì„±ëŠ¥
    test_seeds = [s for s in results["seed_results"].keys() if s != train_seed]
    if test_seeds:
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œë“œ ({len(test_seeds)}ê°œ):")
        
        test_rewards = []
        test_success_rates = []
        
        for seed in test_seeds:
            stats = results["seed_results"][seed]
            test_rewards.append(stats["mean_reward"])
            test_success_rates.append(stats["success_rate"])
            print(f"  ì‹œë“œ {seed}: ë³´ìƒ {stats['mean_reward']:.2f}, ì„±ê³µë¥  {stats['success_rate']*100:.1f}%")
        
        print(f"\n  í‰ê·  ë³´ìƒ: {np.mean(test_rewards):.2f} Â± {np.std(test_rewards):.2f}")
        print(f"  í‰ê·  ì„±ê³µë¥ : {np.mean(test_success_rates)*100:.1f}% Â± {np.std(test_success_rates)*100:.1f}%")
        
        # ì¼ë°˜í™” ì„±ëŠ¥ (í•™ìŠµ ì‹œë“œ ëŒ€ë¹„)
        if train_seed in results["seed_results"]:
            generalization_gap = train_stats["mean_reward"] - np.mean(test_rewards)
            print(f"\nğŸ“‰ ì¼ë°˜í™” ê°­: {generalization_gap:.2f} (í•™ìŠµ ì‹œë“œ - í…ŒìŠ¤íŠ¸ í‰ê· )")
            
            if generalization_gap > 5:
                print("  âš ï¸  ê³¼ì í•© ê°€ëŠ¥ì„± ìˆìŒ")
            elif generalization_gap < -2:
                print("  âœ… ì¼ë°˜í™” ì„±ëŠ¥ ìš°ìˆ˜")
            else:
                print("  âœ… ì ì ˆí•œ ì¼ë°˜í™”")
    
    print("="*60 + "\n")


def save_results(results, filename="evaluation_results.json"):
    """
    í‰ê°€ ê²°ê³¼ ì €ì¥
    
    Args:
        results: í‰ê°€ ê²°ê³¼
        filename: ì €ì¥ íŒŒì¼ëª…
    """
    filepath = get_result_path(filename)
    
    # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    results_json = results.copy()
    for seed, stats in results_json["seed_results"].items():
        stats["episode_rewards"] = [float(r) for r in stats["episode_rewards"]]
        stats["episode_lengths"] = [int(l) for l in stats["episode_lengths"]]
    
    with open(filepath, 'w') as f:
        json.dump(results_json, f, indent=2)
    
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {filepath}")


def create_summary_table(results):
    """
    ê²°ê³¼ë¥¼ í‘œë¡œ ì •ë¦¬
    
    Args:
        results: í‰ê°€ ê²°ê³¼
    
    Returns:
        pd.DataFrame
    """
    data = []
    
    for seed, stats in results["seed_results"].items():
        data.append({
            "Seed": seed,
            "Mean Reward": f"{stats['mean_reward']:.2f}",
            "Std Reward": f"{stats['std_reward']:.2f}",
            "Success Rate": f"{stats['success_rate']*100:.1f}%",
            "Crash Rate": f"{stats['crash_rate']*100:.1f}%",
            "Mean Length": f"{stats['mean_length']:.1f}",
        })
    
    df = pd.DataFrame(data)
    return df


if __name__ == "__main__":
    """
    ë©”ì¸ ì‹¤í–‰
    
    ì‚¬ìš©ë²•:
        # ê¸°ë³¸ í‰ê°€
        python evaluate.py
        
        # íŠ¹ì • ëª¨ë¸ í‰ê°€
        python evaluate.py --model models/ppo_fixed_seed_1000.zip
        
        # ë Œë”ë§ê³¼ í•¨ê»˜ í‰ê°€
        python evaluate.py --render
    """
    import sys
    import argparse
    
    parser = argparse.ArgumentParser(description="PGDrive ëª¨ë¸ í‰ê°€")
    parser.add_argument("--model", type=str, default="models/ppo_fixed_seed_1000.zip",
                       help="í‰ê°€í•  ëª¨ë¸ ê²½ë¡œ")
    parser.add_argument("--seeds", type=int, nargs="+", default=None,
                       help="í…ŒìŠ¤íŠ¸ ì‹œë“œ (ê¸°ë³¸: configì˜ TEST_SEEDS)")
    parser.add_argument("--episodes", type=int, default=20,
                       help="ê° ì‹œë“œë‹¹ ì—í”¼ì†Œë“œ ìˆ˜")
    parser.add_argument("--render", action="store_true",
                       help="ë Œë”ë§ í™œì„±í™”")
    parser.add_argument("--save", type=str, default="evaluation_results.json",
                       help="ê²°ê³¼ ì €ì¥ íŒŒì¼ëª…")
    
    args = parser.parse_args()
    
    # í…ŒìŠ¤íŠ¸ ì‹œë“œ ì„¤ì •
    test_seeds = args.seeds if args.seeds else [FIXED_SEED] + TEST_SEEDS
    
    # í‰ê°€ ì‹¤í–‰
    results = evaluate_model(
        model_path=args.model,
        test_seeds=test_seeds,
        n_episodes=args.episodes,
        render=args.render,
        verbose=True
    )
    
    if results:
        # ì‹œë“œë³„ ë¹„êµ
        compare_seeds(results, train_seed=FIXED_SEED)
        
        # í‘œ ì¶œë ¥
        df = create_summary_table(results)
        print("\nğŸ“‹ ê²°ê³¼ í‘œ:")
        print(df.to_string(index=False))
        print()
        
        # ê²°ê³¼ ì €ì¥
        save_results(results, args.save)
